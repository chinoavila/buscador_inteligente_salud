# DocumentaciÃ³n TÃ©cnica

Esta documentaciÃ³n proporciona detalles tÃ©cnicos sobre la arquitectura, componentes y funcionamiento interno del Buscador Inteligente de Profesionales de Salud.

## ðŸ—ï¸ Arquitectura del Sistema

### Diagrama de Arquitectura
![Diagrama de arquitectura por capas](./images/diagramas/arquitectura_capas.png)

### Diagrama de Componentes

![Diagrama de componentes](./images/diagramas/componentes.png)

### Diagrama de Despliegue

![Diagrama de despliegue](./images/diagramas/despliegue.png)

### Componentes Principales

#### 1. Frontend (Streamlit)
- **Interfaz de usuario** web responsiva
- **GrabaciÃ³n de audio** mediante `audio-recorder-streamlit`
- **VisualizaciÃ³n de resultados** de consulta
- **Manejo de estados** de la aplicaciÃ³n

#### 2. Backend (Python)
- **Procesamiento de audio** y datos
- **IntegraciÃ³n con APIs** externas
- **LÃ³gica de negocio** para busquedas
- **GestiÃ³n de datos** y archivos

#### 3. APIs Externas
- **OpenAI Whisper**: TranscripciÃ³n de audio a texto
- **Hugging Face**: Modelos de procesamiento de lenguaje natural
- **spaCy**: AnÃ¡lisis morfolÃ³gico y entidades nombradas

## ðŸ“‚ Estructura de CÃ³digo

### Directorio principal
```
buscador_inteligente_salud/
â”œâ”€â”€ app.py                 # Punto de entrada de la app (Streamlit)
â”œâ”€â”€ requirements.txt       # Dependencias Python
â”œâ”€â”€ Dockerfile             # Imagen de la aplicaciÃ³n
â”œâ”€â”€ docker-compose.yml     # OrquestaciÃ³n de servicios
â””â”€â”€ README.md              # DocumentaciÃ³n general
```

### AplicaciÃ³n (presentaciÃ³n y orquestaciÃ³n)
```
application/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ ui.py                  # Interfaz de aplicaciÃ³n (Streamlit)
â”œâ”€â”€ orchestration.py       # OrquestaciÃ³n del flujo principal
â”œâ”€â”€ accessibility.py       # Accesibilidad y ayudas visuales
â””â”€â”€ config.py              # ConfiguraciÃ³n y manejo de entorno
```

### MÃ³dulos Funcionales
```
functions/
â”œâ”€â”€ __init__.py              # InicializaciÃ³n del mÃ³dulo
â”œâ”€â”€ transcripcion.py         # TranscripciÃ³n con OpenAI Whisper
â”œâ”€â”€ extraccion.py           # ExtracciÃ³n entidades mÃ©dicas
â””â”€â”€ rag.py                  # LÃ³gica RAG con LangChain
```

### Utilidades
```
utils/
â”œâ”€â”€ __init__.py              # InicializaciÃ³n del mÃ³dulo
â”œâ”€â”€ hf_utils.py             # IntegraciÃ³n Hugging Face
â”œâ”€â”€ spacy_utils.py          # Procesamiento spaCy/scispaCy
â”œâ”€â”€ rag_utils.py            # Utilidades RAG
â””â”€â”€ whisper_utils.py        # Funciones auxiliares para Whisper
```

### Datos
```
datasets/
â””â”€â”€ dataset_ejemplo.xlsx
```

### Persistencia (Vector DB)
```
chroma_db/
â””â”€â”€ ...                     # Persistencia de embeddings en ChromaDB
```

### DocumentaciÃ³n
```
docs/
â”œâ”€â”€ documentacion-tecnica.md      # DocumentaciÃ³n tÃ©cnica detallada
â”œâ”€â”€ guia-de-uso.md              # GuÃ­a de usuario
â”œâ”€â”€ instalacion-detallada.md    # Instrucciones de instalaciÃ³n
â”œâ”€â”€ solucion-problemas.md       # ResoluciÃ³n de problemas
â”œâ”€â”€ images/
â”‚   â””â”€â”€ diagramas/              # Diagramas PNG usados en la doc
â””â”€â”€ plantuml/                   # Diagramas fuente (.puml)
```

## ðŸ”§ Componentes TÃ©cnicos Detallados

Esta secciÃ³n describe los mÃ³dulos del proyecto y sus contratos (entradas/salidas y errores esperados) basados en el cÃ³digo fuente.

### 1) UI y helpers (`application/ui.py`)

- Decorador de estado: `with_status_message(message: str)` muestra un mensaje temporal en la UI mientras se ejecuta la funciÃ³n decorada.
- DiÃ¡logo de ayuda: `show_instructions(max_segundos: int)` abre un modal con instrucciones de uso.
- Entrada de sÃ­ntomas: `create_symptom_input_section()`, `create_styled_radio_input()`, `create_text_input()`, `create_audio_input()`.
- Resultados: `display_results(result_data: dict)` muestra transcripciÃ³n y recomendaciones.
- AcciÃ³n: `create_search_button(text_symptoms: Optional[str], disabled: bool=False)` valida y dispara la bÃºsqueda.

Errores y estados: Usa componentes de Streamlit (info/success/error) y placeholders con `st.empty()`; no lanza excepciones, retorna/actualiza UI.

### 2) OrquestaciÃ³n (`application/orchestration.py`)

Clase principal: `HealthOrchestrator`
- `transcribe_audio(audio_bytes: bytes) -> Optional[str]`
- `process_text_symptoms(text_symptoms: str) -> dict`
- `process_audio_symptoms(audio_bytes: bytes, pretranscription: Optional[str]=None) -> dict`
- `validate_input(input_data: str, min_length: int|None=None) -> tuple[bool, Optional[str]]`

Contrato de `process_*` (salida):
- `success: bool`, `transcription|symptoms_text: str|None`, `entities: str|None`, `recommendations: str|None`, `error_message: str|None`.

Errores manejados: captura excepciones internas y devuelve `error_message` sin romper la UI.

### 3) TranscripciÃ³n (`functions/transcripcion.py` + `utils/whisper_utils.py`)

Flujo:
- `transcribir_audio(bytes) -> str` llama a `utils.whisper_utils.transcribe_audio_with_whisper`.
- `transcribir_con_status(bytes) -> str` aplica el decorador `with_status_message("Transcribiendo audio...")`.

ImplementaciÃ³n Whisper (OpenAI):
```python
from openai import OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
client.audio.transcriptions.create(model="whisper-1", file=io.BytesIO(audio_bytes))
```

Entradas/salidas:
- Entrada: bytes de audio (WAV/MP3/MP4, etc.). Salida: texto.
Errores: propaga como `Exception("Error en transcripciÃ³n con Whisper: ...")` y se capturan en capa superior.

### 4) ExtracciÃ³n de entidades (`functions/extraccion.py`, `utils/spacy_utils.py`, `utils/hf_utils.py`)

Pipeline hÃ­brido:
1) GeneraciÃ³n/normalizaciÃ³n con HF: `generate_with_hugging_face(texto, "es", "en")`.
2) NER con SciSpaCy: `extract_entities_with_spacy(texto_en)` devuelve entidades separadas por coma o mensaje de â€œno detectadoâ€.
3) ClasificaciÃ³n/formateo con HF: `generate_with_hugging_face(entidades, "en", "es")`.

Funciones expuestas:
- `detectar_entidades_medicas(texto: str) -> str`
- `detectar_entidades_con_status(transcripcion: str) -> str`

SciSpaCy (`utils/spacy_utils.py`): `load_model()` cacheado con `st.cache_resource`, modelo `en_core_sci_sm`; `extract_entities_with_spacy(input_text) -> str`.

Hugging Face (`utils/hf_utils.py`):
- Soporta modo remoto (Inference Endpoint) mediante `HF_ENDPOINT_URL` y `HF_TOKEN` y modo local (transformers) con `somosnlp/Sam_Diagnostic`.
- Recorte de salida con marcadores `<start_of_turn>`/`<end_of_turn>`.

Errores tÃ­picos: falta de modelo `en_core_sci_sm`, endpoint HF no configurado, tiempo de espera al generar.

### 5) Sistema RAG (`utils/rag_utils.py` + `functions/rag.py`)

ConfiguraciÃ³n (`Config`):
- Excel: `datasets/dataset_ejemplo.xlsx`
- Embeddings: `text-embedding-3-large`
- Vector DB: `./chroma_db` (Chroma + `PersistentClient`)
- LLM: `gpt-3.5-turbo` (ChatOpenAI), temperatura por defecto 0.3

Componentes:
- `DocumentLoader.load_excel_documents(path) -> list[Document]`
- `VectorStoreManager` crea/carga Chroma con OpenAIEmbeddings
- `PromptBuilder.get_search_prompt()` define formato de respuesta de prestadores
- `RAGProcessor` segmenta (`RecursiveCharacterTextSplitter`), configura retriever y `RetrievalQA`
- `SearchService.search(query) -> str` extrae `medical_specialty` del JSON, arma queries por especialidad, recopila documentos relevantes y responde usando RAG o LLM directo con contexto.
- `get_health_service()` patrÃ³n singleton
- `query_contacts_with_langchain(input_text) -> str`
- `functions/rag.py` expone `consultar_rag(text)` y `consultar_rag_con_status(entidades_medicas)` con decorador de estado.

Errores y bordes:
- Vectorstore inexistente: se crea si hay documentos; si no, devuelve â€œNo se encontraron resultadosâ€.
- Excel inaccesible: excepciÃ³n al cargar; el orquestador traduce a `error_message`.
- Consulta sin especialidad: usa bÃºsqueda general con tÃ©rminos amplios.

### 6) ConfiguraciÃ³n y variables de entorno relevantes

- `OPENAI_API_KEY`: requerido para Whisper y Embeddings/LLM de OpenAI.
- `HF_TOKEN`, `HF_ENDPOINT_URL`: opcionales para usar endpoint remoto de HF.
- Modelo SciSpaCy `en_core_sci_sm`: debe estar instalado en el entorno.

### 7) Contratos y casos lÃ­mite resumidos

- Audio vacÃ­o/no vÃ¡lido: transcripciÃ³n falla y retorna `error_message` de orquestaciÃ³n.
- Texto muy corto: `validate_input` fuerza mÃ­nimo (config) y advierte en UI.
- Sin entidades detectadas: mensaje sugerente para mejorar la descripciÃ³n.
- RAG sin documentos relevantes: respuesta estÃ¡ndar â€œNo se encontraron resultadosâ€¦â€.

## ðŸ”„ Flujo de Datos

### Vista general del flujo

![Flujo de procesamiento de extremo a extremo](./images/diagramas/flujo_procesamiento.png)

### Secuencia: TranscripciÃ³n de Audio

![Diagrama de secuencia de transcripciÃ³n](./images/diagramas/secuencia_transcripcion.png)

### Secuencia: ExtracciÃ³n de Entidades

![Diagrama de secuencia de extracciÃ³n](./images/diagramas/secuencia_extraccion.png)

### Secuencia: Sistema RAG

![Diagrama de secuencia RAG](./images/diagramas/secuencia_rag.png)

## ðŸ“¦ Dependencias y TecnologÃ­as

### Dependencias principales (requirements)

#### Framework y UI
- streamlit>=1.28.0 â€” framework web para la interfaz de usuario
- audio-recorder-streamlit==0.0.10 â€” componente de grabaciÃ³n de audio

#### APIs y ML
- openai>=1.0.0 â€” cliente oficial para Whisper y modelos GPT/Embeddings
- transformers>=4.30.0,<4.40.0 â€” inferencia local (HF); usado en modo local de `hf_utils`
- huggingface_hub>=0.19.0 â€” cliente del Hub de Hugging Face (descargas/modelos)
- torch>=2.0.0,<2.5.0 â€” backend de inferencia para transformers (CPU/GPU)
- spacy>=3.7.0,< 3.8.0 â€” NLP general; base para SciSpaCy
- spacy-lookups-data==1.0.5 â€” tablas de lookup para spaCy

#### RAG y LangChain
- langchain==0.3.27 â€” orquestaciÃ³n de LLMs y chains
- langchain-openai>=0.1.0 â€” integraciÃ³n de OpenAI (Chat/Embeddings)
- langchain-community>=0.2.0 â€” loaders y utilidades de la comunidad
- langchain-chroma>=0.1.2 â€” integraciÃ³n con ChromaDB
- chromadb>=0.5.0,<0.6.0 â€” base de datos vectorial (PersistentClient)

#### Datos y utilidades
- pandas>=1.5.0,< 3.0.0 â€” manejo de datos tabulares (Excel)
- numpy>=1.24.0,<2.0.0 â€” cÃ³mputo numÃ©rico
- openpyxl>=3.1.0 â€” lectura de archivos .xlsx
- python-dotenv==1.0.0 â€” carga de variables de entorno
- requests>=2.31.0 â€” llamadas HTTP (HF Endpoints)

#### Modelo especializado (SciSpaCy)
- en_core_sci_sm (SciSpaCy v0.5.4) â€” modelo biomÃ©dico para NER basado en spaCy
  - InstalaciÃ³n desde URL en requirements: https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz

### Stack tecnolÃ³gico RAG

#### Vector database
- ChromaDB (>=0.5,<0.6) con persistencia en `./chroma_db`
- Embeddings por defecto: OpenAI `text-embedding-3-large` (vÃ­a `langchain-openai`)

#### Componentes LangChain
- Carga de documentos: desde Excel (pandas) â†’ `Document`
- Particionado: `RecursiveCharacterTextSplitter` (chunk_size 1000, overlap 100)
- Retriever y QA: `RetrievalQA` con `ChatOpenAI` y prompt especializado

#### Modelos de lenguaje
- ChatOpenAI: `gpt-3.5-turbo` para generaciÃ³n contextualizada
- OpenAI Embeddings: `text-embedding-3-large` para vectorizaciÃ³n
- NER biomÃ©dico auxiliar: `somosnlp/Sam_Diagnostic` (transformers) en modo local o vÃ­a endpoint HF

### Notas de compatibilidad y entorno
- Variables: requiere `OPENAI_API_KEY`; opcionales `HF_TOKEN` y `HF_ENDPOINT_URL` para endpoints remotos de HF.
- GPU (opcional): si hay CUDA disponible, `torch` y `transformers` pueden acelerar la inferencia local.

### ProtecciÃ³n de datos sensibles
- API keys en `.env`, sin exponer en cÃ³digo ni logs.
- Audio en memoria; sin persistencia del archivo de entrada.
- Transcripciones y resultados manejados en sesiÃ³n; evitar PII en logs.

## ðŸ§© Extensibilidad

### Nuevos Modelos
Para agregar modelos de ML:
1. Crear funciÃ³n en `utils/`
2. Registrar en pipeline principal
3. Documentar cambios

### Nuevas Funcionalidades
Estructura para extensiones:
```python
# utils/nueva_funcionalidad.py
def nueva_funcion():
    """DocumentaciÃ³n de la nueva funciÃ³n"""
    pass

# IntegraciÃ³n en app.py
from utils.nueva_funcionalidad import nueva_funcion
```

### APIs Adicionales
Para integrar nuevos servicios:
1. Agregar credenciales a `.env`
2. Crear mÃ³dulo de integraciÃ³n
3. Manejar errores especÃ­ficos
4. Actualizar documentaciÃ³n
